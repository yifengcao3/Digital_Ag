{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c322ecd7-6dcf-470c-89e0-abdfaa181540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # data manipulation and analysis\n",
    "import os # to get absolute path\n",
    "import datetime # to get current date\n",
    "from sklearn.ensemble import RandomForestClassifier # for creating a random forest classification model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc # to calculate the accuracy of the model\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs # for performing stepwise feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2be452f5-f7f9-4297-8840-dad35eceb782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (3673, 10) (3673,)\n",
      "Testing dataset shape: (1225, 10) (1225,)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "# absolute path: npath = \"/Users/tanlab/Desktop/YC_Selection_02_14_2024/Data/Raw/winequality-white.csv\"\n",
    "# absolute path: npath = os.path.abspath(os.pardir)+\"//Data/Raw/winequality-white.csv\"\n",
    "\n",
    "# We want the codes also work on other computers, so relative path will be our first choice.\n",
    "npath = '../Data/Raw/winequality-white.csv' # relative path\n",
    "df = pd.read_csv(npath,index_col = 0, sep=';') # This dataset seperates with \";\"\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.values[:,:-1], # This takes all rows and all columns except the last one (data)\n",
    "    df.values[:,-1:], # This selects all rows and only the last column (result - quality)\n",
    "    test_size = 0.25,\n",
    "    random_state = 42) # This sets a seed for the random number generator\n",
    "\n",
    "y_train = y_train.ravel() # The ravel method is used to reduce a multidimensional array to a one-dimensional array\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('Training dataset shape:', X_train.shape, y_train.shape) # shape - to view the dimensions of an array\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f995998-a8e6-4fcb-9f4d-658cba2eeac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   25.8s finished\n",
      "\n",
      "[2024-02-14 14:24:51] Features: 1/5 -- score: 0.49468683386161005[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   23.7s finished\n",
      "\n",
      "[2024-02-14 14:25:15] Features: 2/5 -- score: 0.5442462325529667[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   23.4s finished\n",
      "\n",
      "[2024-02-14 14:25:38] Features: 3/5 -- score: 0.6038625368403492[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   22.7s finished\n",
      "\n",
      "[2024-02-14 14:26:01] Features: 4/5 -- score: 0.619919924373019[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   16.7s finished\n",
      "\n",
      "[2024-02-14 14:26:18] Features: 5/5 -- score: 0.6387054440304732"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 6, 7, 9]\n",
      "Training accuracy on selected features: 0.558\n",
      "Testing accuracy on selected features: 0.513\n",
      "Training accuracy on all features: 0.567\n",
      "Testing accuracy on all features: 0.514\n"
     ]
    }
   ],
   "source": [
    "# Repeat k_features = 5\n",
    "\n",
    "# Build RF classifier to use in feature selection\n",
    "clf = RandomForestClassifier(n_estimators = 100, n_jobs = -1) \n",
    "# n_estimators=100 - The number of decision trees to be used by the model is 100\n",
    "# n_jobs = -1 - When set to -1, the algorithm uses all available cores on your computer\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(clf,\n",
    "           k_features = 5, # Using k_features = 5. Number of features finally selected is 6 here\n",
    "           forward = True,\n",
    "           floating = False,\n",
    "           verbose = 2,\n",
    "           scoring = 'accuracy',\n",
    "           cv = 5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "# Our best performing model, given our scoring metric, is some subset of 5 features, with a score of 0.635\n",
    "\n",
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols) # The columns at these indexes are those which were selected\n",
    "\n",
    "# Build full model with selected features\n",
    "clf = RandomForestClassifier(n_estimators = 1000, random_state = 42, max_depth = 4) # A bigger tree, still use pevious seed\n",
    "clf.fit(X_train[:, feat_cols], y_train) # X_train[:, feat_cols] - only use the features we selected\n",
    "\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols]) # Also only use the features we selected\n",
    "print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))\n",
    "\n",
    "# Build full model on ALL features, for comparison\n",
    "clf = RandomForestClassifier(n_estimators = 1000, random_state = 42, max_depth = 4) # Same setting as above\n",
    "clf.fit(X_train, y_train) # Here we use all features\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print('Training accuracy on all features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print('Testing accuracy on all features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76cb2ab6-4bab-440b-8385-cf265277b07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   20.2s finished\n",
      "\n",
      "[2024-02-14 14:27:33] Features: 1/6 -- score: 0.49414150401304935[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   26.3s finished\n",
      "\n",
      "[2024-02-14 14:27:59] Features: 2/6 -- score: 0.5472379469498971[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   26.6s finished\n",
      "\n",
      "[2024-02-14 14:28:25] Features: 3/6 -- score: 0.6022291423381342[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   34.0s finished\n",
      "\n",
      "[2024-02-14 14:28:59] Features: 4/6 -- score: 0.6237357504309625[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   29.2s finished\n",
      "\n",
      "[2024-02-14 14:29:29] Features: 5/6 -- score: 0.6370787224971732[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   24.0s finished\n",
      "\n",
      "[2024-02-14 14:29:53] Features: 6/6 -- score: 0.641977052401342"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 6, 7, 9]\n",
      "Training accuracy on selected features: 0.561\n",
      "Testing accuracy on selected features: 0.512\n",
      "Training accuracy on all features: 0.567\n",
      "Testing accuracy on all features: 0.514\n"
     ]
    }
   ],
   "source": [
    "# When k_features = 6\n",
    "\n",
    "# Build RF classifier to use in feature selection\n",
    "clf = RandomForestClassifier(n_estimators = 100, n_jobs = -1) \n",
    "# n_estimators=100 - The number of decision trees to be used by the model is 100\n",
    "# n_jobs = -1 - When set to -1, the algorithm uses all available cores on your computer\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(clf,\n",
    "           k_features = 6, # Using k_features = 6. Number of features finally selected is 6 here\n",
    "           forward = True,\n",
    "           floating = False,\n",
    "           verbose = 2,\n",
    "           scoring = 'accuracy',\n",
    "           cv = 5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "# Our best performing model, given our scoring metric, is some subset of 6 features, with a score of 0.644 \n",
    "\n",
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols) # The columns at these indexes are those which were selected. Results change here\n",
    "\n",
    "# Build full model with selected features\n",
    "clf = RandomForestClassifier(n_estimators = 1000, random_state = 42, max_depth = 4) # A bigger tree, still use pevious seed\n",
    "clf.fit(X_train[:, feat_cols], y_train) # X_train[:, feat_cols] - only use the features we selected\n",
    "\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols]) # Also only use the features we selected\n",
    "print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))\n",
    "\n",
    "# Build full model on ALL features, for comparison\n",
    "clf = RandomForestClassifier(n_estimators = 1000, random_state = 42, max_depth = 4) # Same setting as above\n",
    "clf.fit(X_train, y_train) # Here we use all features\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print('Training accuracy on all features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print('Testing accuracy on all features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d43faa8d-6c1e-4428-8b02-bbb10aaf5f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics saved to ../Results//YC_Description_02_14_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate descriptive statistics\n",
    "description = df.describe()\n",
    "\n",
    "# Get current date\n",
    "current_month = datetime.datetime.now().strftime(\"%m\")\n",
    "current_date = datetime.datetime.now().strftime(\"%d\")\n",
    "current_year = datetime.datetime.now().strftime(\"%Y\")\n",
    "\n",
    "# I set a relative path to put the \"Description\" file to the \"Results\" folder\n",
    "directory_path = '../Results/' # relative path\n",
    "\n",
    "# Define file name\n",
    "file_name = f\"{directory_path}/YC_Description_{current_month}_{current_date}_{current_year}.csv\"\n",
    "\n",
    "# Save descriptive statistics to CSV\n",
    "description.to_csv(file_name)\n",
    "\n",
    "print(f\"Descriptive statistics saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36cd6d-619f-4f69-9c78-34dac12b3b04",
   "metadata": {},
   "source": [
    "# **The description of the output:**\\\n",
    "  In this practice, we first used a small random forest to identify five or six features, simplifying the model by reducing the number of features. Then, we employed a larger random forest to test the accuracy. The results showed that the accuracy using only five or six features was also high, only slightly lower than the accuracy achieved using all features.\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
